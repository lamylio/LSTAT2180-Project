---
title: "Dev.Book"
author: "Lamy Lionel, Kinart Adrien"
---

# Retrieve and format the sample 

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)

n = 30 
p = 0.5
sample = as.data.frame(read.csv("data/sample.csv"))
sample = sample %>% rename("ID" = X, "obs" = x) %>% arrange(obs)

distribution = table(sample %>% summarize(obs))/n

```
# Data description
## PArameters of interest
```{r parameters_of_interest}
theta_F = (1-p)^3
mu_hat = mean(sample$obs)
p_hat = 1/ (mu_hat+1) 
T_p = (1-p_hat)^3 # T(X) in the parametric case

T_n = 1 - 1/30 * (sum(sample$obs<=2)) # = T(X) in the non paramatric case 
```

## Comparing Densities

```{r}
x = seq(0, max(sample$obs), 1)
ggplot(mapping=aes(x)) +
  labs(title = "Estimated density vs Real density") +
  geom_col(aes(y=distribution), width = 0.05)  + 
  geom_point(aes(y=dgeom(x,p)), colour="blue", shape=1, size=2) +
  geom_line(aes(y=dgeom(x, p)), colour="blue") + 
  scale_y_continuous()

```

## Comparing Real CDF and Estimated CDF.

```{r}
ggplot(mapping=aes(x)) +
  labs(title="Empirical CDF vs Real CDF", y = "cum.probability") +
  geom_point(mapping = aes(y=pgeom(x,p)), colour="blue", shape=1, size=2) + 
  geom_line(mapping = aes(y=pgeom(x,p)), colour="blue") +
  stat_ecdf(geom="step", pad=F,mapping=aes(x=sample$obs))
```
## Disitrubtion
Faire l'équivalent de la figure 1.8. du sylla:
Tout ce qui est possible de mettre: 
- assumed parametric model (fait)
- assumed parametric normal approx 
- assumed paratric bootsrap approx 
- non parametric normal approx
- non parametruc bootsrap approx(fait)

```{r }
nb_sim = 100000
true_est <- rep(NA, nb_sim)
for (i in 1:100000) {
  Xtrue<-rgeom(n=30, prob=0.5 ) # true distribution
  p_true <- (mean(Xtrue)+1)^(-1)
  true_est[i] = (1-p_true)^3
}

p_bootstrap = rep(NA,nb_sim)
for (i in 1:nb_sim) {
  Xstar <- sample(x=sample$obs, size=30, replace=T)
  p_bootstrap[i] <- 1 - 1/30 * (sum(Xstar<=2))
}
#lines(density(p_bootstrap), col= 'green', type="l", lty=2)
#legend("topright", legend=c("true", "Bootstrap"), col=c("blue", "green"), lty=1:2, cex=0.8)
hist(p_bootstrap, probability = T) # Geometric est discrete donc c est normal qu'il y ait des blancs je pense
lines(density(true_est), col= 'blue', type="l", main="Densities", lty=1  , xlab="p" )
abline(v=theta_F, col= 'green')

```


# EStimator quality in the non parametric case : Bias and variance
```{r bootstrap_settings}
B=1000
```
## Bias
```{r Bias estimation via bootstrap}
first_term_B <-0
  for (i in 1:B) {
    set.seed(i)
    Xstar = sample(x=sample$obs, size=n, replace=T)
    first_term_B <- first_term_B + (1/B)*( 1 - 1/30 * (sum(Xstar<=2)) )
  }
approx_bias <- first_term_B - T_n
```
##Variance
```{r Bias estimation via bootstrap}
Var_boot <-0
  for (i in 1:B) {
    set.seed(i)
    Xstar = sample(x=sample$obs, size=n, replace=T)
    first = (1/B)*( 1 - 1/30 * (sum(Xstar<=2)) )^2
    second = ((1/B)*(1-1/30*(sum(Xstar<=2))))^2 
    Var_boot <- Var_boot + (first-second)
  }

```



# Confidence intervals
## Parametric environments:
Here, we believe in the function distribution of $X$ with a geometric distribution.
### Assymptotically normal
```{r parametric AN }
Q1AN <- (2*n*mu_hat +2*n - qchisq(p=0.05, df=1))/(2*n*(mu_hat+1)^2)
Q2AN <- 1/2 * sqrt(  (4*n*mu_hat^2*qchisq(p=0.05,df=1)+4*n*mu_hat*qchisq(p=0.05,df=1)^2)/(n^2*(mu_hat+1)^4))
CI_param_AN <- c((1-(Q1AN+Q2AN))^3, (1-(Q1AN-Q2AN))^3)
CI_param_AN
```

### Basic and percentile bootstrap
<!-- Not modified (except sample$obs) -->
```{r}
alpha = 0.05
B = 5000

B_distri_of_T <- rep(NA,B) # constitue la distribution de T(X) dont on va choper les quantiles

for (i in 1:B) {
  Xstar <- rgeom(n=30, prob = p_hat) # on genere ici car on est dans le cas parametrique
  mu_star <- mean(Xstar)
  Tstar <- ( 1-(mu_star+1)^(-1) )^3
  B_distri_of_T[i] <- Tstar
}
CI_param_boot <- c(2*T_p - quantile(B_distri_of_T, 1-alpha/2), 2*T_p - quantile(B_distri_of_T, alpha/2))
CI_percen_boot <- c(quantile(B_distri_of_T, alpha/2), quantile(B_distri_of_T, 1-alpha/2))

hist(B_distri_of_T)
CI_param_boot
CI_percen_boot
```


### Student t bootstrap
<!-- je me suis inspirer de https://www.textbook.ds100.org/ch/18/hyp_studentized.html -->
```{r}
alpha = 0.05
B1 = 5000
B2=50

StB_distri_of_T <- rep(NA,B1) # constitue la distribution de T(X) dont on va choper les quantiles

for (i in 1:B1) {
  Xstar <- rgeom(n=30, prob = p_hat) # on genere ici car on est dans le cas parametrique
  mu_star <- mean(Xstar)
  Tstar <- ( 1-(mu_star+1)^(-1) )^3
  vec_T_star <- rep(NA,B2) # sert uniquement à trouver la standard error de la statistiques bootstrapée
  for (j in 1:B2) {
    Xstar_star <- sample(x=Xstar, size= length(Xstar), replace=T)
    mu_star_star <- mean(Xstar_star)
    vec_T_star[j] <-  ( 1-(mu_star_star+1)^(-1) )^3
  }
  SE_Tstar <- sd(vec_T_star)/sqrt(B2)
  StB_distri_of_T[i] = (Tstar - mean(vec_T_star))/SE_Tstar
}
SE_theta_hat <- sd(StB_distri_of_T)/sqrt(B1)
CI_st_B <- c(T_p - quantile(StB_distri_of_T, 0.975)*SE_theta_hat,T_p - quantile(StB_distri_of_T, 0.025)*SE_theta_hat )
CI_st_B
```


## Non-arametric environments:
# Assymptotic 


<!-- 
The cleanest option, imho, is to handle each task in a specific file (ie. "basic-bootstrap.R")
and to call it here by typing: source("path_to_file.R")
-->