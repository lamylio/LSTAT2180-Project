---
title: "Dev.Book"
author: "Lamy Lionel, Kinart Adrien"
---

# Retrieve and format the sample 
```{r message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)

set.seed(112021)

sample = as.data.frame(read.csv("data/sample.csv"))
sample = sample %>% rename("ID" = X, "obs" = x) %>% arrange(obs)

```

```{r utils}
T.param = function(obs){return ((1 - (1/(mean(obs)+1)) )^3)}
T.nonparam = function(obs){return (sum(obs>=3)/length(obs))}

n = 30 
p = 0.5
B = 5000
alpha = 0.05
```

# Data description
## Parameters of interest
```{r parameters_of_interest}
theta = dgeom(2, p)  # (1-p)^3 == 0.125 # TRUE THETA

sample.mu = mean(sample$obs)
sample.p = 1/(sample.mu+1) # /!\ c'est le plug in estimator seulement dans le cas paramtrique !!!!!!! 

# Be careful : I used the name theta for the estimator T(X)
sample.theta.param = T.param(sample$obs)
sample.theta.nonparam = T.nonparam(sample$obs)
```

## Comparing Densities

```{r}
sample.distribution = table(sample %>% summarize(obs))/n

x = seq(0, max(sample$obs), 1)
ggplot(mapping=aes(x)) +
  labs(title = "Estimated density vs Real density") +
  geom_col(aes(y=sample.distribution), width = 0.05)  + 
  geom_point(aes(y=dgeom(x,p)), colour="blue", shape=1, size=2) +
  geom_line(aes(y=dgeom(x, p)), colour="blue") + 
  scale_y_continuous()

```

## Comparing Real CDF and Estimated CDF.

```{r}
ggplot(mapping=aes(x)) +
  labs(title="Empirical CDF vs Real CDF", y = "cum.probability") +
  geom_point(mapping = aes(y=pgeom(x,p)), colour="blue", shape=1, size=2) + 
  geom_line(mapping = aes(y=pgeom(x,p)), colour="blue") +
  stat_ecdf(geom="step", pad=F,mapping=aes(x=sample$obs))
```
## Distribution
Faire l'équivalent de la figure 1.8. du sylla:
Tout ce qui est possible de mettre: 
- assumed parametric model (fait)
- assumed parametric normal approx 
- assumed paratric bootsrap approx 
- non parametric normal approx
- non parametruc bootsrap approx(fait)

```{r }

(function(B=100000){
  geomTheta = rep(NA, B)
  bootTheta = rep(NA, B)
  for (i in 1:B){
    set.seed(i)
    geomSample = rgeom(n, p)
    geomTheta[i] = T.param(geomSample)  
    
    bootSample = sample(sample$obs, n, T)
    bootTheta[i] = T.nonparam(bootSample)
  }
  
  geomDensity = density(geomTheta)
  hist(bootTheta, probability = T, xlab = "Theta", main = "Histogram Theta ")
  lines(dgeom(1:B, p), col = "blue", type="l")
  abline(v=theta, col="green")
})()
```


# Estimator quality in the non parametric case : Bias and variance
## Bias
```{r Bias estimation}
bootstrap.bias = (function(B=5000){
  bootTheta = rep(NA, B)
  for (i in 1:B){
    set.seed(i)
    bootSample = sample(sample$obs, n, T)
    bootTheta[i] = T.nonparam(bootSample)
  }
  return (mean(bootTheta) - sample.theta.nonparam)
})()
```
## Variance
```{r Variance estimation}

bootstrap.var = (function(B=5000){
  
  bootSquaredTheta = rep(NA, B)
  bootTheta = rep(NA, B)
  for (i in 1:B){
    set.seed(i)
    bootSample = sample(sample$obs, n, T)
    bootTheta[i] = T.nonparam(bootSample)
    bootSquaredTheta[i] = bootTheta[i]^2
  }
  
  bootSquaredTheta = mean(bootSquaredTheta)
  bootThetaSquared = mean(bootTheta)^2
  
  return (bootSquaredTheta - bootThetaSquared)
  
})()
bootstrap.var
```

## Check for normality of t(X) in non parametric environment
Allows to check if normality assumption for Theta(F_n) is reasonable
```{r}
Boot_theta.np <- rep(NA,B)
for (i in 1:B) {
  bootSample = sample(sample$obs, n, T)
  Boot_theta.np[i] = T.nonparam(bootSample)
}
{
qqnorm(Boot_theta.np, main = "Normal quantile line against boostraped empirical quantile line")
legend("topleft", legend = c('empirical quantiles', 'Normal quantile'), col = c('black','steelblue'), 
       lty = c(1,1), lwd = 2)
qqline(Boot_theta.np, col = "steelblue", lwd = 2)
}
```
Seems like normality is not respected for such distribution. 



# Confidence intervals
## CI Parametric environments:
Here, we believe in the function distribution of $X$ with a geometric distribution.
### Check for normality in param. envir. 
````{r normalityCheckPE}
require(tseries)
B=1000
Boot_theta.p <- rep(NA,B)
for (i in 1:B) {
  set.seed(i)
  bootSample = rgeom(30,p)
  Boot_theta.p[i] = T.param(bootSample)
}
{
qqnorm(Boot_theta.p, main = "Normal quantile line against MC quantile line in parametric environment")
legend("topleft", legend = c('MC quantiles', 'Normal quantile'), col = c('black','steelblue'), 
       lty = c(1,1), lwd = 2)
qqline(Boot_theta.p, col = "steelblue", lwd = 2)
}
jarque.bera.test(Boot_theta.p)
```



### CI Assymptotically normal (par)
<<<<<<< HEAD
```{r parametric AN }
# https://stats.stackexchange.com/questions/310413/confidence-interval-using-central-limit-theorem 
Q1AN <- (2*n*sample.mu +2*n - qchisq(1-alpha, df=1))/(2*n*(sample.mu+1)^2)
Q2AN <- 1/2 * sqrt(  (4*n*sample.mu^2*qchisq(1-alpha,df=1)+4*n*sample.mu*qchisq(1-alpha,df=1)^2)/(n^2*(sample.mu+1)^4))
CI_param_AN <- c((1-(Q1AN+Q2AN))^3, (1-(Q1AN-Q2AN))^3)
CI_param_AN
```

=======

```{r parametric AN }
CI.param.normal = (function(){
  
  Q1 = (2*n*sample.mu + 2*n - qchisq(1-alpha, 1)) / (2*n * (sample.mu + 1)^2)
  Q2 = 0.5 * sqrt((4*n * sample.mu^2 * qchisq(1-alpha, 1) + 4*n*sample.mu * qchisq(1-alpha, 1)^2) / (n^2*(sample.mu + 1)^4))
  
  low = (1-(Q1+Q2))^3
  upp = (1-(Q1-Q2))^3
  
  return (c(low, upp))
})()
```


>>>>>>> af1f69cbbef9335aadd19ac65c15a467050d36ca

### CI BB and PBl (par)

```{r CI Parametric boostrap}

boostrap.param = function(B=5000){
  
  bootTheta = rep(NA, B)
  for (i in 1:B){
    bootSample =  rgeom(n, prob = sample.p)
    bootTheta[i] = T.param(bootSample)
  }
  return (bootTheta)
}

CI.param = (function(){
  
  bootTheta = boostrap.param()
  quantiles = quantile(bootTheta, c(1-alpha/2, alpha/2))
  
  CI.basic = c(2*sample.theta.param - quantiles[1], 2*sample.theta.param - quantiles[2])
  CI.percent = c(quantiles[2], quantiles[1])
  
  return (data.frame("basic"=CI.basic, "percent"=CI.percent))
})()

CI.param.basic = CI.param$basic
CI.param.percent = CI.param$percent
rm(CI.param)
```

<!-----------------
        TODO 
------------------->

### Student t bootstrap (par)
```{r}
alpha = 0.05
B1 = 5000
StB_distri_of_T <- rep(NA,B1) # Distribution de T(X) dont on va choper les quantiles
# !!!!!!!! MAUVAIS  !!!!!!!!!!!!!!!!!!# !!!!!!!! MAUVAIS  !!!!!!!!!!!!!!
SE_Tstar.p <- sd(sample$obs)/sqrt(n)  # !!!!!!!! MAUVAIS  !!!!!!!!!!!!!!
# !!!!!!!! MAUVAIS  !!!!!!!!!!!!!!!!!!# !!!!!!!! MAUVAIS  !!!!!!!!!!!!!!
for (i in 1:B1) {
  set.seed(i)
  Xstar <- rgeom(n=30, prob = sample.p) # on genere ici car on est dans le cas parametrique
  mu_star <- mean(Xstar)
  Tstar <- ( 1-(mu_star+1)^(-1) )^3
  StB_distri_of_T[i] = (Tstar - sample.theta.nonparam)/SE_Tstar.p }

CI_st_B <- c(sample.theta.param - quantile(StB_distri_of_T, 0.975)*SE_Tstar.p,
             sample.theta.param - quantile(StB_distri_of_T, 0.025)*SE_Tstar.p )
CI_st_B
```
### Iterated bootstrap (par)
<!-- je me suis inspiré de https://www.textbook.ds100.org/ch/18/hyp_studentized.html -->
```{r}
alpha = 0.05
B1 = 5000
B2=50

It_StB_distri_of_T <- rep(NA,B1) # constitue la distribution de T(X) dont on va choper les quantiles

for (i in 1:B1) {
  set.seed(i)
  Xstar <- rgeom(n=30, prob = sample.p) # on genere ici car on est dans le cas parametrique. Par contre je ne sais pas s'il faut utiliser sample.p ou le 'p' réelle. 
  mu_star <- mean(Xstar)
  Tstar <- ( 1-(mu_star+1)^(-1) )^3
  vec_T_star <- rep(NA,B2) # sert uniquement à trouver la standard error de la statistiques bootstrapée
  for (j in 1:B2) {
    Xstar_star <- sample(x=Xstar, size= length(Xstar), replace=T)
    mu_star_star <- mean(Xstar_star)
    vec_T_star[j] <-  ( 1-(mu_star_star+1)^(-1) )^3
  }
  SE_Tstar <- sd(vec_T_star)/sqrt(B2)
  It_StB_distri_of_T[i] = (Tstar - mean(vec_T_star))/SE_Tstar
}
It_SE_theta_hat <- sd(It_StB_distri_of_T)/sqrt(B1)
CI_It_st_B <- c(sample.theta.param - quantile(It_StB_distri_of_T, 0.975)*It_SE_theta_hat,
                sample.theta.param - quantile(It_StB_distri_of_T, 0.025)*It_SE_theta_hat )
CI_It_st_B
```












## CI Non-parametric environments:





### CI AN np
```{r}
CI.np.AN <- c(T.nonparam(sample$obs)-qnorm(0.975)*sqrt(bootstrap.var), # page 42 sylla
              T.nonparam(sample$obs)+qnorm(0.975)*sqrt(bootstrap.var) )
CI.np.AN
```


### Basic and percentile Bootstrap CI (np)

```{r BBandPBinNP}
B=5000
CI.np.basic = function(){
  T = rep(NA, B)
}

CI.np.basic.T = rep(NA, B)
for (i in 1:B){
  set.seed(i)
  CI.np.basic.resample = sample(sample$obs, n, T)
  CI.np.basic.T[i] = sum(CI.np.basic.resample>=3)/30 }

CI.np.basic.quantiles = quantile(CI.np.basic.T, c(alpha/2, 1-alpha/2))

CI.np.basic = c(2*sample.theta.nonparam - CI.np.basic.quantiles[2], 
                2*sample.theta.nonparam - CI.np.basic.quantiles[1])
CI.np.percentil <- CI.np.basic.quantiles

CI.np.basic
CI.np.percentil
```
### CI T-bootstrap (np)
```{r}
B=5000
CI.np.student = function(){ T = rep(NA, B)}
np.T = rep(NA, B)
for (i in 1:B){
  set.seed(i)
  np.resample = sample(sample$obs, n, T)
  np.T[i] = sum(np.resample>=3)/30 
}

SE_student_np <- sd(sample$obs)/sqrt(n)
CI.np.studentB <- c(sample.theta.nonparam - quantile(np.T, 0.975)*SE_student_np,
                    sample.theta.nonparam - quantile(np.T, 0.025)*SE_student_np)
CI.np.studentB

```

### CI iterated T-bootstrap (np)
```{r IteratedBoostrapNP}
B1 = 5000
B2=50

np.T_studentized <- rep(NA,B1) # constitue la distribution de T(X) dont on va choper les quantiles

for (i in 1:B1) {
  set.seed(i)
  Xstar <- sample(sample$obs,n,TRUE)
  while (max(Xstar)<3) { # Obligé de rajouter ça sinon on obtient Tstar = 0. En faisant ça, on fait l'hypothès que P(X>=3) >0
    Xstar <- sample(sample$obs,n,TRUE) }
  Tstar <- T.nonparam(Xstar)
  vec_T_star <- rep(NA,B2) # sert uniquement à trouver la standard error de la statistiques bootstrapée
  for (j in 1:B2) {
    Xstar_star <- sample(x=Xstar, size= length(Xstar), replace=TRUE)
    #while (max(Xstar_star)<3) { Xstar_star <- sample(sample$obs,n,TRUE) } # bon là, pas besoin de mettre ça (logique mathématqiuement )
    vec_T_star[j] <-  T.nonparam(Xstar_star)
  }
  SE_Tstar <- sd(vec_T_star)/sqrt(B2) # B2 = length(vec_T_star)
  np.T_studentized[i] = (Tstar - mean(vec_T_star))/SE_Tstar
  if(is.na(np.T_studentized[i])){
    print('check:')
    print(Tstar)
    print(Xstar_star)
    print(Xstar)
    }
}
It_SE_theta_hat_np <- sd(np.T_studentized)/sqrt(B1) # length(np.T_studentized) = B1
CI_It_st_B_np <- c(sample.theta.nonparam - quantile(np.T_studentized, 0.975)*It_SE_theta_hat_np,
                sample.theta.nonparam - quantile(np.T_studentized, 0.025)*It_SE_theta_hat_np )
CI_It_st_B_np
```






# Hypothesis testing


```{r thetaZERO}
theta_zero_statisfied <- 0.05
theta_zero_unstatisfied <- 0.3
```

## Tests
### non parametrique
- Statisfied hypothesis (np)
$$
\text{H}_0: \theta =0.125 \\
\text{H}_1: \theta \neq 0.125 
$$

```{r}
T.np.vec <- rep(NA, B)
for (i in 1:B) {
  set.seed(i)
  Xstar <- sample(sample$obs,n, TRUE)
  T.np.vec[i] <- T.nonparam(Xstar)}

if (quantile(T.np.vec, 0.025)< theta_zero_statisfied   & theta_zero_statisfied < quantile(T.np.vec, 0.975) ){
  print("Fail to reject null hypothesis")
} else{print("Reject null hypothesis") }

```



- Untatisfied hypothesis

$$
\text{H}_0: \theta =0.3 \\
\text{H}_1: \theta \neq 0.3 
$$ 


```{r}
## MAUVAIS JE SAIS PAS COMMMENT FAIRE
T.testing <- rep(NA, B)
tweaked_sample <- rep(NA,n)
for (i in 1:n) {
  new_sample <- sample(sample$obs, n, TRUE)
  tweaked_sample[i] <- quantile(new_sample, probs = 0.7)
}
T.nonparam(tweaked_sample)

```

```{r}

if (quantile(T.np.vec, 0.025)< theta_zero_unstatisfied   & theta_zero_unstatisfied < quantile(T.np.vec, 0.975) ){
  print("Fail to reject null hypothesis")
} else{print("Reject null hypothesis") }

``` 
### Power 

```{r}
low_bond_power <- 0.05
upp_bond_power <- 0.3 
theta_zero_power_vec <- seq(from=low_bond_power, to=upp_bond_power)
power_vec <- rep(NA,length(theta_zero_power_vec))

for (p in 1:length(theta_zero_power_vec)) {
  T.np.vec <- rep(NA, B)
  for (i in 1:B) {
    set.seed(i)
    Xstar <- sample(sample$obs,n, TRUE)
    T.np.vec[i] <- T.nonparam(Xstar)}
  
  #lower_bond <-  quantile(T.np.vec, 0.025) 
  #upper_bond <- quantile(T.np.vec, 0.975) 
  #power_vec[p] <- 1- #Nb de fois (on garde H0 | H_a) / B
}
```







# Coverage study


```{r coverageSettings}
n1 <- 10
n2 <- 50
n3 <- 500
N <- c(n1,n2,n3)
p=0.5
M=500
B <- 500
```




## Coverage parametric


## coverage AN (par)
```{r CoverageANinPar}
coverage.param.AN <- rep(1,length(N))
names(coverage.param.AN) <- c('10','50','500')

for (sample_size in 1:length(N)){
  for (m in 1:M){
    set.seed(m)
    new_sample <- rgeom(N[sample_size], p)
    new_sample.mu <- mean(new_sample)
    
    Q1AN <- (2*N[sample_size]*new_sample.mu +2*N[sample_size] - qchisq(p=1-alpha, df=1))/(2*N[sample_size]*(new_sample.mu+1)^2)
    Q2AN <- 1/2 * sqrt(  (4*N[sample_size]*new_sample.mu^2*qchisq(p=1-alpha,df=1)+4*N[sample_size]*new_sample.mu*qchisq(p=1-alpha,df=1)^2)/(N[sample_size]^2*(new_sample.mu+1)^4))
    CI.param.AN <- c((1-(Q1AN+Q2AN))^3, (1-(Q1AN-Q2AN))^3)
    
    if ( 0.125<= CI.param.AN[1] || 0.125>= CI.param.AN[2]) {
      coverage.param.AN[sample_size] <- coverage.param.AN[sample_size]- 1/M }
  }
}
coverage.param.AN


```

## coverage BB an PB (par)
```{r}
coverage.param.BB <- rep(1,length(N))
names(coverage.param.BB) <- c('10','50','500')
coverage.param.PB <- rep(1,length(N))
names(coverage.param.PB) <- c('10','50','500')

for (sample_size in 1:length(N)){
  for (m in 1:M){
    #set.seed(m)
    new_sample <- rgeom(N[sample_size], p)
    T_star.param <- T.param(new_sample)
    
    bootTheta = rep(NA, B)
    for (i in 1:B){
      #set.seed(i*m)
      bootSample =  rgeom(N[sample_size], p)
      bootTheta[i] = T.param(bootSample)}
    
    quantiles = quantile(bootTheta, c(1-alpha/2, alpha/2))
    
    CI.basic.param = c(2*T_star.param - quantiles[1], 2*T_star.param - quantiles[2])
    CI.percent.param = c(quantiles[2], quantiles[1])
    
    if ( 0.125< CI.basic.param[1] || 0.125> CI.basic.param[2]) {
      coverage.param.BB[sample_size] <- coverage.param.BB[sample_size]- 1/M }
    
    if ( 0.125< CI.percent.param[1] || 0.125> CI.percent.param[2]) {
      coverage.param.PB[sample_size] <- coverage.param.PB[sample_size]- 1/M }
  }
}

coverage.param.BB
coverage.param.PB

```


## coverage t-boot (par)

## coverage IB (par)
```{r CoverageTBinNP}
M <- 100
B1 <- 100
B2<- 50

coverage.param.IB <- rep(1,length(N))
names(coverage.param.IB) <- c('10','50','500')

for (sample_size in 1:length(N)){
  for (m in 1:M){
    set.seed(m) 
    new_sample <- rgeom(N[sample_size], p)
    #while (max(new_sample)<3) { new_sample <- rgeom(N[sample_size], p) }
    new_sample.mu = mean(new_sample)
    new_sample.p = 1/(new_sample.mu+1) 
    T_x <- T.param(new_sample)
    param.T_studentized <- rep(NA,B1) # constitue la distribution de T(X) dont on va choper les quantiles
    for (i in 1:B1) {
      set.seed(i*m)
      Xstar <- rgeom(n=N[sample_size], prob = new_sample.p) # on genere ici car on est dans le cas parametrique. Par contre je ne sais pas s'il faut utiliser sample.p ou le 'p' réelle. 
      while (max(Xstar<=0) || length(unique(Xstar))<=1 ){Xstar <- rgeom(n=N[sample_size], prob = new_sample.p)}
      mu_star <- mean(Xstar)
      Tstar <- ( 1-(mu_star+1)^(-1) )^3
      vec_T_star <- rep(NA,B2) # sert uniquement à trouver la standard error de la statistiques bootstrapée
      for (j in 1:B2) {
        Xstar_star <- sample(x=Xstar, size= length(Xstar), replace=T)
        mu_star_star <- mean(Xstar_star)
        vec_T_star[j] <-  ( 1-(mu_star_star+1)^(-1) )^3
      }
      SE_Tstar <- sd(vec_T_star)/sqrt(B2)
      param.T_studentized[i] = (Tstar - mean(vec_T_star))/SE_Tstar
      if(is.na(param.T_studentized[i])){
        print(Tstar)
        print(vec_T_star)
        print(SE_Tstar)
        stop()
      }
    }
    It_SE_theta_hat <- sd(param.T_studentized)/sqrt(B1)
    CI_It_st_B_param <- c(T_x - quantile(param.T_studentized, 0.975)*It_SE_theta_hat,
                    T_x - quantile(param.T_studentized, 0.025)*It_SE_theta_hat )
    
    if ( 0.125<= CI_It_st_B_param[1] || 0.125>= CI_It_st_B_param[2]) {
      coverage.param.IB[sample_size] <- coverage.param.IB[sample_size]- 1/M }
  }
  
}
coverage.param.IB
```






## Non Parametric coverage


### AN (np)

```{r CoverageANinNP}
coverage.np.AN <- rep(1,length(N))
names(coverage.np.AN) <- c('10','50','500')

for (sample_size in 1:length(N)){
  for (m in 1:M){
    set.seed(m)
    new_sample <- rgeom(N[sample_size], p)
    bootSquaredTheta = rep(NA, B)
    bootTheta = rep(NA, B)
    for (i in 1:B){
      set.seed(i*m)
      bootSample = sample(new_sample, N[sample_size], TRUE)
      bootTheta[i] = T.nonparam(bootSample) 
      bootSquaredTheta[i] = bootTheta[i]^2
      }
    bootstrap.var <-  mean(bootSquaredTheta) - mean(bootTheta)^2
    CI.np.AN <- c(T.nonparam(new_sample)-qnorm(0.975)*sqrt(bootstrap.var), # page 42 sylla
                T.nonparam(new_sample)+qnorm(0.975)*sqrt(bootstrap.var) )
    if ( 0.125<= CI.np.AN[1] || 0.125>= CI.np.AN[2]) {
      coverage.np.AN[sample_size] <- coverage.np.AN[sample_size]- 1/M }
  }
}
coverage.np.AN
```
### BB and PB
```{r CoverageBBinNP}
coverage.np.BB <- rep(1,length(N))
names(coverage.np.BB) <- c('10','50','500')

coverage.np.PB <- rep(1,length(N))
names(coverage.np.PB) <- c('10','50','500')

for (sample_size in 1:length(N)){
  for (m in 1:M){
    set.seed(m) 
    new_sample <- rgeom(N[sample_size], p)
    T.np.distri = rep(NA, B)
    for (i in 1:B){
      set.seed(i*m)
      CI.np.basic.resample = sample(new_sample, N[sample_size], TRUE)
      T.np.distri[i] =T.nonparam(CI.np.basic.resample) }
    
    CI.np.quantiles = quantile(T.np.distri, c(alpha/2, 1-alpha/2))
  
    
    CI.np.BB = c(2*T.nonparam(new_sample) - CI.np.quantiles[2], 
                    2*T.nonparam(new_sample) - CI.np.quantiles[1])
    if ( 0.125<= CI.np.BB[1] || 0.125>= CI.np.BB[2]) {
      coverage.np.BB[sample_size] <- coverage.np.BB[sample_size]- 1/M }
  
    
    CI.np.percentil <- CI.np.quantiles
    if ( 0.125<= CI.np.percentil[1] || 0.125>= CI.np.percentil[2]) {
      coverage.np.PB[sample_size] <- coverage.np.PB[sample_size]- 1/M }
  
  }
}
coverage.np.BB
coverage.np.PB
```

- TB ==> Ca n'a pas l'air de fonctionnner 
```{r CoverageTBinNP}

coverage.np.TB <- rep(1,length(N))
names(coverage.np.TB) <- c('10','50','500')

for (sample_size in 1:length(N)){
  for (m in 1:M){
    set.seed(m) 
    new_sample <- rgeom(N[sample_size], p)
    np.T = rep(NA, B)
    for (i in 1:B){
      set.seed(i*m)
      np.resample = sample(new_sample, N[sample_size], TRUE)
      np.T[i] = T.nonparam(np.resample) }

    SE_student_np <- sd(new_sample)/sqrt(N[sample_size])
    CI.np.studentB <- c(T.nonparam(new_sample) - quantile(np.T, 0.975)*SE_student_np,
                        T.nonparam(new_sample) - quantile(np.T, 0.025)*SE_student_np)
    
    if ( 0.125<= CI.np.studentB[1] || 0.125>= CI.np.studentB[2]) {
      coverage.np.TB[sample_size] <- coverage.np.TB[sample_size]- 1/M }
  }
}
coverage.np.TB
```


- IB

```{r CoverageTBinNP}
M <- 100
B1 <- 100
B2<- 50

coverage.np.TB <- rep(1,length(N))
names(coverage.np.TB) <- c('10','50','500')

for (sample_size in 1:length(N)){
  for (m in 1:M){
    set.seed(m) 
    new_sample <- rgeom(N[sample_size], p)
    while (max(new_sample)<3) { new_sample <- rgeom(N[sample_size], p) }
    
    np.T_studentized <- rep(NA,B1) # constitue la distribution de T(X) dont on va choper les quantiles

    for (i in 1:B1) {
      set.seed(i*m)
      Xstar <- sample(new_sample,n,TRUE)
      while (max(Xstar)<3) { Xstar <- sample(new_sample,n,TRUE) }
      Tstar <- T.nonparam(Xstar)
      vec_T_star <- rep(NA,B2) # sert uniquement à trouver la standard error de la statistiques bootstrapée
      for (j in 1:B2) {
        set.seed(i*m*j)
        Xstar_star <- sample(x=Xstar, size= length(Xstar), replace=TRUE)
        vec_T_star[j] <-  T.nonparam(Xstar_star)
      }
      SE_Tstar <- sd(vec_T_star)/sqrt(B2) # B2 = length(vec_T_star)
      np.T_studentized[i] = (Tstar - mean(vec_T_star))/SE_Tstar
      
    }
    It_SE_theta_hat_np <- sd(np.T_studentized)/sqrt(B1) # length(np.T_studentized) = B1
    CI_It_st_B_np <- c(T.nonparam(new_sample) - quantile(np.T_studentized, 0.975)*It_SE_theta_hat_np,
                       T.nonparam(new_sample) - quantile(np.T_studentized, 0.025)*It_SE_theta_hat_np )
    
    if ( 0.125<= CI_It_st_B_np[1] || 0.125>= CI_It_st_B_np[2]) {
      coverage.np.TB[sample_size] <- coverage.np.TB[sample_size]- 1/M }
  }
  
}
coverage.np.TB
```


