---
title: "Dev.Book"
author: "Lamy Lionel, Kinart Adrien"
---

# Retrieve and format the sample 

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)

set.seed(112021)

sample = as.data.frame(read.csv("data/sample.csv"))
sample = sample %>% rename("ID" = X, "obs" = x) %>% arrange(obs)

```

```{r utils}
T.param = function(obs){return ((1 - (1/(mean(obs)+1)) )^3)}
T.nonparam = function(obs){return (sum(obs>=3)/length(obs))}

n = 30 
p = 0.5
B = 5000
alpha = 0.05
```

# Data description
## Parameters of interest
```{r parameters_of_interest}
theta = dgeom(2, p)  # (1-p)^3 == 0.125

sample.mu = mean(sample$obs)
sample.p = 1/(sample.mu+1)

# Be careful : I used the name theta for the estimator T(X)
sample.theta.param = T.param(sample$obs)
sample.theta.nonparam = T.nonparam(sample$obs)
```

## Comparing Densities

```{r}
sample.distribution = table(sample %>% summarize(obs))/n

x = seq(0, max(sample$obs), 1)
ggplot(mapping=aes(x)) +
  labs(title = "Estimated density vs Real density") +
  geom_col(aes(y=sample.distribution), width = 0.05)  + 
  geom_point(aes(y=dgeom(x,p)), colour="blue", shape=1, size=2) +
  geom_line(aes(y=dgeom(x, p)), colour="blue") + 
  scale_y_continuous()

```

## Comparing Real CDF and Estimated CDF.

```{r}
ggplot(mapping=aes(x)) +
  labs(title="Empirical CDF vs Real CDF", y = "cum.probability") +
  geom_point(mapping = aes(y=pgeom(x,p)), colour="blue", shape=1, size=2) + 
  geom_line(mapping = aes(y=pgeom(x,p)), colour="blue") +
  stat_ecdf(geom="step", pad=F,mapping=aes(x=sample$obs))
```
## Distribution
Faire l'équivalent de la figure 1.8. du sylla:
Tout ce qui est possible de mettre: 
- assumed parametric model (fait)
- assumed parametric normal approx 
- assumed paratric bootsrap approx 
- non parametric normal approx
- non parametruc bootsrap approx(fait)

```{r }

(function(B=100000){
  
  geomTheta = rep(NA, B)
  bootTheta = rep(NA, B)
  for (i in 1:B){
    geomSample = rgeom(n, p)
    geomTheta[i] = T.param(geomSample)  
    
    bootSample = sample(sample$obs, n, T)
    bootTheta[i] = T.nonparam(bootSample)
  }
  
  geomDensity = density(geomTheta)
  hist(bootTheta, probability = T, xlab = "Theta", main = "Histogram Theta ")
  lines(dgeom(1:B, p), col = "blue", type="l")
  abline(v=theta, col="green")
})()
```


# Estimator quality in the non parametric case : Bias and variance


## Bias
```{r Bias estimation}

bootstrap.bias = (function(B=5000){
  
  bootTheta = rep(NA, B)
  for (i in 1:B){
    bootSample = sample(sample$obs, n, T)
    bootTheta[i] = T.nonparam(bootSample)
  }
  
  return (mean(bootTheta) - sample.theta.nonparam)
})()
```
## Variance
```{r Variance estimation}

bootstrap.var = (function(B=5000){
  
  bootSquaredTheta = rep(NA, B)
  bootTheta = rep(NA, B)
  for (i in 1:B){
    bootSample = sample(sample$obs, n, T)
    bootTheta[i] = T.nonparam(bootSample)
    bootSquaredTheta[i] = bootTheta[i]^2
  }
  
  bootSquaredTheta = mean(bootSquaredTheta)
  bootThetaSquared = mean(bootTheta)^2
  
  return (bootSquaredTheta - bootThetaSquared)
  
})()
```

# Confidence intervals
## Parametric environments:
Here, we believe in the function distribution of $X$ with a geometric distribution.

### Assymptotically normal
<<<<<<< HEAD
```{r parametric AN }
Q1AN <- (2*n*mu_hat +2*n - qchisq(p=0.05, df=1))/(2*n*(mu_hat+1)^2)
Q2AN <- 1/2 * sqrt(  (4*n*mu_hat^2*qchisq(p=0.05,df=1)+4*n*mu_hat*qchisq(p=0.05,df=1)^2)/(n^2*(mu_hat+1)^4))
CI_param_AN <- c((1-(Q1AN+Q2AN))^3, (1-(Q1AN-Q2AN))^3)
CI_param_AN
```

=======

```{r parametric AN }
CI.param.normal = (function(){
  
  Q1 = (2*n*sample.mu + 2*n - qchisq(alpha, 1)) / (2*n * (sample.mu + 1)^2)
  Q2 = 0.5 * sqrt((4*n * sample.mu^2 * qchisq(alpha, 1) + 4*n*sample.mu * qchisq(alpha, 1)^2) / (n^2*(sample.mu + 1)^4))
  
  low = (1-(Q1+Q2))^3
  upp = (1-(Q1-Q2))^3
  
  return (c(low, upp))
})()
```


>>>>>>> af1f69cbbef9335aadd19ac65c15a467050d36ca
### Basic and percentile bootstrap

```{r CI Parametric boostrap}

boostrap.param = function(B=5000){
  
  bootTheta = rep(NA, B)
  for (i in 1:B){
    bootSample =  rgeom(n, prob = sample.p)
    bootTheta[i] = T.param(bootSample)
  }
  return (bootTheta)
}

CI.param = (function(){
  
  bootTheta = boostrap.param()
  quantiles = quantile(bootTheta, c(1-alpha/2, alpha/2))
  
  CI.basic = c(2*sample.theta.param - quantiles[1], 2*sample.theta.param - quantiles[2])
  CI.percent = c(quantiles[2], quantiles[1])
  
  return (data.frame("basic"=CI.basic, "percent"=CI.percent))
})()

CI.param.basic = CI.param$basic
CI.param.percent = CI.param$percent
rm(CI.param)
```

<!-----------------
        TODO 
------------------->

### Student t bootstrap
<!-- je me suis inspiré de https://www.textbook.ds100.org/ch/18/hyp_studentized.html -->
```{r}
alpha = 0.05
B1 = 5000
B2=50

StB_distri_of_T <- rep(NA,B1) # constitue la distribution de T(X) dont on va choper les quantiles

for (i in 1:B1) {
  Xstar <- rgeom(n=30, prob = p_hat) # on genere ici car on est dans le cas parametrique
  mu_star <- mean(Xstar)
  Tstar <- ( 1-(mu_star+1)^(-1) )^3
  vec_T_star <- rep(NA,B2) # sert uniquement à trouver la standard error de la statistiques bootstrapée
  for (j in 1:B2) {
    Xstar_star <- sample(x=Xstar, size= length(Xstar), replace=T)
    mu_star_star <- mean(Xstar_star)
    vec_T_star[j] <-  ( 1-(mu_star_star+1)^(-1) )^3
  }
  SE_Tstar <- sd(vec_T_star)/sqrt(B2)
  StB_distri_of_T[i] = (Tstar - mean(vec_T_star))/SE_Tstar
}
SE_theta_hat <- sd(StB_distri_of_T)/sqrt(B1)
CI_st_B <- c(T_p - quantile(StB_distri_of_T, 0.975)*SE_theta_hat,T_p - quantile(StB_distri_of_T, 0.025)*SE_theta_hat )
CI_st_B
```


## Non-parametric environments:
# Basic Bootstrap CI

```{r}

CI.basic = function(){
  T = rep(NA, B)
}

B=5000
CI.basic.T = rep(NA, B)
for (i in 1:B){
  CI.basic.resample = sample(sample$obs, 30, T)
  #CI.basic.resample.mean = mean(CI.basic.resample)
  CI.basic.T[i] = sum(CI.basic.resample>=3)/30
}

CI.basic.quantiles = quantile(CI.basic.T, c(alpha/2, 1-alpha/2))
CI.basic = c(2*T_n - CI.basic.quantiles[2], 2*T_n - CI.basic.quantiles[1])
CI.basic
```



