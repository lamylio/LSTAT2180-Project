---
title: "Resampling"
author: "Lamy Lionel"
date: "06/01/2021"
output: html_document
---

```{r options, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r setup}
library(dplyr)
library(ggplot2)

set.seed(2021)

n = 30 
p = 0.5
M = 50000

alpha = 0.05
theta = dgeom(2, p)

T.param = function(obs){return (round((1 - (1/(mean(obs)+1)) )^3, 4))}
T.nonparam = function(obs){return (round(sum(obs>=3)/length(obs), 4))}

sample = rgeom(n=30, prob=0.5)
sample.distribution = prop.table(table(sample))

sample.mu = mean(sample)
sample.p = 1/(sample.mu+1)

sample.T.param = T.param(sample)
sample.T.nonparam = T.nonparam(sample)

# ---
export.list = c("sample", "n", "p", "M", "alpha", "theta", "sample.mu", "sample.p","T.param", "T.nonparam", "sample.T.param", "sample.T.nonparam")

```

# Parallelization

```{r parallel}
library(parallel)
cl <<- makeCluster(min(4, detectCores()))
clusterExport(cl, export.list)
```

# Batch of boostrapped samples (parallelized)

```{r boot}
T.boot = function(T.function, this.n=n, this.sample=NULL){
  if (!is.null(this.sample)){
    parSapply(cl, 1:M, function (i) T.nonparam(sample(this.sample, this.n, T)))
  }else{
    parSapply(cl, 1:M, function (i) T.param(rgeom(this.n, p)))
  }
}


T.nonparam.boot = T.boot(T.nonparam, this.sample = sample)
T.param.boot = T.boot(T.param, this.n = n)
```


# Bias and variance

```{r bias and variance}
bias.nonparam = mean(T.nonparam.boot - theta)
bias.param = mean(T.param.boot - theta)

# We can simply use built-in function var(x) but.. 
variance = function(this.boot.T) mean(this.boot.T^2 - mean(this.boot.T)^2)
variance.nonparam = variance(T.nonparam.boot)
variance.param = variance(T.param.boot)
```

# Check for normality

```{r normality check}
# Graphically with barplots
# Works also with plot(density())

barplot(table(T.nonparam.boot))
barplot(table(T.param.boot))

# Now in a QQPlot

qqnorm(T.nonparam.boot); qqline(T.nonparam.boot, col=2)
qqnorm(T.param.boot); qqline(T.param.boot, col=2)

```

# Give a confidence interval

## Asymptotic method

```{r asymptotic CI}
CI.param.asym = function(this.mu=sample.mu, this.n=n){
  
  Q1 = (2*this.n*this.mu + 2*this.n - qchisq(1-alpha, 1)) / (2*this.n*(this.mu + 1)^2)
  Q2 = 0.5 * sqrt((4*this.n*this.mu^2 * qchisq(1-alpha, 1) + 4*this.n*this.mu * qchisq(1-alpha, 1)^2) / (n^2*(this.mu + 1)^4))
  
  low = (1-(Q1+Q2))^3
  upp = (1-(Q1-Q2))^3
  
  data.frame(low, upp)
}

CI.nonparam.asym = function(this.sample.T = sample.T.nonparam, this.variance = variance.nonparam){
  upp = this.sample.T + qnorm(1-alpha/2) * sqrt(this.variance)
  low = this.sample.T - qnorm(1-alpha/2) * sqrt(this.variance)
  data.frame(low, upp)
}
```

## Percentile boostrap method

```{r percentile CI}
CI.percent = function(this.boot.T) quantile(this.boot.T, c(alpha/2, 1-alpha/2))

CI.percent.param = CI.percent(T.param.boot)
CI.percent.nonparam = CI.percent(T.nonparam.boot)
```

## Basic boostrap method

```{r basic CI}
CI.basic = function(this.boot.T, this.sample.T) data.frame(low=2*this.sample.T - CI.percent(this.boot.T)[2], upp= 2*this.sample.T - CI.percent(this.boot.T)[1])

CI.basic.param = CI.basic(T.param.boot, sample.T.param)
CI.basic.nonparam = CI.basic(T.nonparam.boot, sample.T.nonparam)
```

## T-boostrap method
<!-- A vérifier ?? -->

```{r student CI}
CI.student = function(this.boot.T, this.sample.T, this.sample = sample, this.n = n) data.frame(
  low=this.sample.T - quantile(this.boot.T, 1-alpha/2) * (sd(this.sample)/sqrt(this.n)), 
  upp=this.sample.T - quantile(this.boot.T, alpha/2) * (sd(this.sample)/sqrt(this.n))
)

CI.student.param = CI.student(T.param.boot, sample.T.param)
CI.student.nonparam = CI.student(T.nonparam.boot, sample.T.nonparam)
```

## Iterated-T boostrap method

```{r iterated CI}
# TODO : parallelize
# Est-ce que ça reviendrait pas au même que de directement sampler dans T.x.boot ? 
# Btw je ne vois pas en quoi le fait que TStar = 0 soit un problème mmh
CI.iterated = function(sampleFunction, M2 = M/100){
  
  iterated = sapply(1:M, function(i){
  
    boot = sampleFunction
    TStar = sapply(seq(1,M2), function(j){
      bootSample = sample(boot, n, T)
      T.param(bootSample)
    })
    
    TStar.SE = sd(TStar)/sqrt(M2)
    
    (T.param(boot) - mean(TStar))/TStar.SE
  })
  
  iterated.SE = sd(iterated)/sqrt(M)
  data.frame(low=sample.T.param - quantile(iterated, 1-alpha/2) * iterated.SE,
             upp=sample.T.param - quantile(iterated, alpha/2) * iterated.SE, row.names = NULL)
  
}

CI.iterated.param = CI.iterated(sampleFunction = rgeom(n, p))
CI.iterated.nonparam = CI.iterated(sampleFunction = sample(sample, n, T))


```

# Hypothesis test

## Satisfied

```{r satisfied}
#TODO
```

## Rejected

```{r rejected}
#TODO
```



# Coverage of confidence interval

```{r coverage setup}

```



```{r coverage}
#TODO
m = c(10,100,500,1000)
B = 50

# On ne fait pas l'iterated dans le coverage

cover = function(confidence){
  (confidence$low <= theta & theta <= confidence$upp)
}

coverage = data.frame()
for (n_i in m){
  coverage.loc = sapply(1:B, function(i) {
    
    newSample = rgeom(n_i, p)
    
    newSample.mu = mean(newSample)
    newSample.var = var(newSample)
    newSample.T = T.param(newSample)
    
   # ---
    
    c(
      cover(CI.param.asym(newSample.mu, n_i)),
      cover(CI.nonparam.asym(newSample.T, newSample.var)),
      cover(CI.basic(T.boot(T.param, this.n = n_i), newSample.T)),
      cover(CI.basic(T.boot(T.nonparam, this.sample = newSample), newSample.T))
      # TODO: le reste
    )
    
  })
  coverage = rbind(coverage, rowMeans(coverage.loc)*100)
  
 
   
}
colnames(coverage) = c("Asymp. param", "Asym. np", "Basic. param", "Basic. np")
```


```{r end}
# Close clusters
stopCluster(cl)
```

